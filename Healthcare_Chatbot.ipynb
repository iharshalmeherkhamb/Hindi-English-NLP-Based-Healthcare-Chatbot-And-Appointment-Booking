{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da96fb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ File loaded successfully!\n",
      "\n",
      "--- Column Names ---\n",
      "['Unnamed: 0', 'Disease', 'Symptom_1', 'Symptom_2', 'Symptom_3', 'Symptom_4', 'Remedies']\n",
      "\n",
      "--- First 3 Rows ---\n",
      "   Unnamed: 0           Disease   Symptom_1              Symptom_2  \\\n",
      "0           0  Fungal infection     itching              skin_rash   \n",
      "1           1  Fungal infection   skin_rash   nodal_skin_eruptions   \n",
      "2           2  Fungal infection     itching   nodal_skin_eruptions   \n",
      "\n",
      "               Symptom_3             Symptom_4  \\\n",
      "0   nodal_skin_eruptions   dischromic _patches   \n",
      "1    dischromic _patches                   NaN   \n",
      "2    dischromic _patches                   NaN   \n",
      "\n",
      "                                            Remedies  \n",
      "0  Apply antifungal cream, keep area dry, avoid t...  \n",
      "1  Apply antifungal cream, keep area dry, avoid t...  \n",
      "2  Apply antifungal cream, keep area dry, avoid t...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the specific dataset\n",
    "filename = 'symptoms_with_remedies.xlsx'\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(filename)\n",
    "    print(\"‚úÖ File loaded successfully!\")\n",
    "    \n",
    "    # Check the column names to understand the text structure\n",
    "    print(\"\\n--- Column Names ---\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    # Check the first few rows to understand the content\n",
    "    print(\"\\n--- First 3 Rows ---\")\n",
    "    print(df.head(3))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Could not find '{filename}'. Make sure it is in the same folder as your notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "109a762a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Enriched with Doctor Details!\n",
      "            Disease                                  Combined_Symptoms  \\\n",
      "0  Fungal infection  itching,  skin_rash,  nodal_skin_eruptions,  d...   \n",
      "1  Fungal infection   skin_rash,  nodal_skin_eruptions,  dischromic...   \n",
      "2  Fungal infection  itching,  nodal_skin_eruptions,  dischromic _p...   \n",
      "\n",
      "    Doctor_Name           Doctor_Location  \n",
      "0  Dr. P. Verma  Skin Care Clinic, Mumbai  \n",
      "1  Dr. P. Verma  Skin Care Clinic, Mumbai  \n",
      "2  Dr. P. Verma  Skin Care Clinic, Mumbai  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. CLEANING: Fill missing values with empty strings\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# 2. NLP PRE-PROCESSING: Combine all symptoms into one text column for easier matching\n",
    "# We create a 'Description' column that the NLP model will search against\n",
    "df['Combined_Symptoms'] = df['Symptom_1'] + \", \" + df['Symptom_2'] + \", \" + df['Symptom_3'] + \", \" + df['Symptom_4']\n",
    "\n",
    "# 3. FEATURE ENGINEERING: Create the Missing Doctor Data\n",
    "# We define a mapping logic: Disease Category -> Specialist\n",
    "def assign_doctor(disease):\n",
    "    disease = disease.lower()\n",
    "    if 'heart' in disease or 'cardio' in disease:\n",
    "        return {'Specialist': 'Cardiologist', 'Name': 'Dr. A. Sharma', 'Time': '10:00 AM - 2:00 PM', 'Location': 'City Heart Center, Delhi'}\n",
    "    elif 'fungal' in disease or 'skin' in disease or 'rash' in disease:\n",
    "        return {'Specialist': 'Dermatologist', 'Name': 'Dr. P. Verma', 'Time': '4:00 PM - 8:00 PM', 'Location': 'Skin Care Clinic, Mumbai'}\n",
    "    elif 'stomach' in disease or 'digestion' in disease:\n",
    "        return {'Specialist': 'Gastroenterologist', 'Name': 'Dr. R. Gupta', 'Time': '11:00 AM - 3:00 PM', 'Location': 'Digestive Care, Bangalore'}\n",
    "    else:\n",
    "        # Default General Physician for other diseases\n",
    "        return {'Specialist': 'General Physician', 'Name': 'Dr. S. Kumar', 'Time': '9:00 AM - 5:00 PM', 'Location': 'City Hospital, Main Wing'}\n",
    "\n",
    "# Apply this logic to create new columns\n",
    "doctor_info = df['Disease'].apply(assign_doctor)\n",
    "df['Doctor_Name'] = doctor_info.apply(lambda x: x['Name'])\n",
    "df['Doctor_Specialist'] = doctor_info.apply(lambda x: x['Specialist'])\n",
    "df['Doctor_Time'] = doctor_info.apply(lambda x: x['Time'])\n",
    "df['Doctor_Location'] = doctor_info.apply(lambda x: x['Location'])\n",
    "\n",
    "# Show the new enhanced dataset\n",
    "print(\"‚úÖ Data Enriched with Doctor Details!\")\n",
    "print(df[['Disease', 'Combined_Symptoms', 'Doctor_Name', 'Doctor_Location']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac448b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\ihars\\anaconda3\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.8.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.24.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2022.9.14)\n",
      "Loading free embedding model... (This might take a minute)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihars\\AppData\\Local\\Temp\\ipykernel_26100\\2534124731.py:11: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7faa7a801cd4442c909bd2b2c4c1e84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihars\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ihars\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa7a33c85ed4391a2a0dd314c1f0d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc78902d6a4d49d7a6db9f6aefec61d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e980ecca9d4e119d3cbaf5b7c6ceb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a30bd1d99b840b994bb40ec47f11c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05464697f6b44544aea07d377b94ed55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9dddb70f4e4913996c0838f068ca89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294d886ed3c241f982363adf6adf6144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a92c02226645f68849d9e10b9bd071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20852d5600144cc80d5b65f0235b3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09f4df52c5a4340ae25578c349baf50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Vector Database...\n",
      "‚ùå Error: Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version).\n"
     ]
    }
   ],
   "source": [
    "# 1. Install the library for free embeddings\n",
    "!pip install sentence-transformers\n",
    "\n",
    "# 2. Import necessary libraries\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 3. Initialize the Free Embedding Model\n",
    "# This runs locally on your CPU (no API key needed)\n",
    "print(\"Loading free embedding model... (This might take a minute)\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# 4. Create the Vector Database\n",
    "try:\n",
    "    print(\"Creating Vector Database...\")\n",
    "    # 'documents' is the list we created in the previous step\n",
    "    vector_db = FAISS.from_documents(documents, embeddings)\n",
    "    print(\"‚úÖ Vector Database created successfully using HuggingFace!\")\n",
    "    print(\"The AI is now ready to search your data for free.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c70bfe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\ihars\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas64__v0.3.21-gcc_10_3_0.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.0-cp39-cp39-win_amd64.whl (18.7 MB)\n",
      "     ---------------------------------------- 18.7/18.7 MB 8.6 MB/s eta 0:00:00\n",
      "Collecting numpy<3.0,>=1.25.0\n",
      "  Using cached numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\ihars\\anaconda3\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Installing collected packages: numpy, faiss-cpu\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23296\\3905559995.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 2. Re-import everything (Necessary after restart)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# numpy compat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_numpy_dev\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m from pandas.compat.numpy import (\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mnp_version_under1p19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# numpy versioning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m from pandas.util._decorators import (  # noqa:F401\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mAppender\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mSubstitution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcache_readonly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcache_readonly\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m from pandas._libs.tslibs import (\n\u001b[0;32m     15\u001b[0m     \u001b[0mNaT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\interval.pyx\u001b[0m in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# 1. Ensure FAISS is installed\n",
    "!pip install faiss-cpu\n",
    "\n",
    "# 2. Re-import everything (Necessary after restart)\n",
    "import pandas as pd\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# 3. Re-load your dataframe (Since memory was cleared)\n",
    "df = pd.read_excel('symptoms_with_remedies.xlsx')\n",
    "df.fillna('', inplace=True)\n",
    "df['Combined_Symptoms'] = df['Symptom_1'] + \", \" + df['Symptom_2'] + \", \" + df['Symptom_3'] + \", \" + df['Symptom_4']\n",
    "\n",
    "# Re-create the doctor logic\n",
    "def assign_doctor(disease):\n",
    "    disease = disease.lower()\n",
    "    if 'heart' in disease or 'cardio' in disease:\n",
    "        return {'Specialist': 'Cardiologist', 'Name': 'Dr. A. Sharma', 'Time': '10:00 AM - 2:00 PM', 'Location': 'City Heart Center, Delhi'}\n",
    "    elif 'fungal' in disease or 'skin' in disease or 'rash' in disease:\n",
    "        return {'Specialist': 'Dermatologist', 'Name': 'Dr. P. Verma', 'Time': '4:00 PM - 8:00 PM', 'Location': 'Skin Care Clinic, Mumbai'}\n",
    "    elif 'stomach' in disease or 'digestion' in disease:\n",
    "        return {'Specialist': 'Gastroenterologist', 'Name': 'Dr. R. Gupta', 'Time': '11:00 AM - 3:00 PM', 'Location': 'Digestive Care, Bangalore'}\n",
    "    else:\n",
    "        return {'Specialist': 'General Physician', 'Name': 'Dr. S. Kumar', 'Time': '9:00 AM - 5:00 PM', 'Location': 'City Hospital, Main Wing'}\n",
    "\n",
    "doctor_info = df['Disease'].apply(assign_doctor)\n",
    "df['Doctor_Name'] = doctor_info.apply(lambda x: x['Name'])\n",
    "df['Doctor_Specialist'] = doctor_info.apply(lambda x: x['Specialist'])\n",
    "df['Doctor_Time'] = doctor_info.apply(lambda x: x['Time'])\n",
    "df['Doctor_Location'] = doctor_info.apply(lambda x: x['Location'])\n",
    "\n",
    "# 4. Prepare Documents again\n",
    "documents = []\n",
    "for index, row in df.iterrows():\n",
    "    searchable_text = f\"Disease: {row['Disease']}. Symptoms: {row['Combined_Symptoms']}\"\n",
    "    meta_data = {\n",
    "        \"disease\": row['Disease'],\n",
    "        \"remedies\": row['Remedies'],\n",
    "        \"doc_name\": row['Doctor_Name'],\n",
    "        \"doc_spec\": row['Doctor_Specialist'],\n",
    "        \"doc_time\": row['Doctor_Time'],\n",
    "        \"doc_loc\": row['Doctor_Location']\n",
    "    }\n",
    "    doc = Document(page_content=searchable_text, metadata=meta_data)\n",
    "    documents.append(doc)\n",
    "\n",
    "# 5. Create Vector DB\n",
    "print(\"Loading Model & Creating Database...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_db = FAISS.from_documents(documents, embeddings)\n",
    "print(\"‚úÖ Success! Vector Database is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3494c7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0.0\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "     --------------------------------------- 15.8/15.8 MB 10.7 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\ihars\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy.libs\\\\libscipy_openblas64_-caad452230ae4ddb57899b8b3a33c55c.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy<2.0.0\" --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c4296b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Embedding Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ihars\\AppData\\Local\\Temp\\ipykernel_452\\400460807.py:31: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vectors for all diseases... (This takes a moment)\n",
      "Building Search Engine...\n",
      "‚úÖ Success! The chatbot brain is ready.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# 1. LOAD DATA (Standard steps)\n",
    "df = pd.read_excel('symptoms_with_remedies.xlsx')\n",
    "df.fillna('', inplace=True)\n",
    "df['Combined_Symptoms'] = df['Symptom_1'] + \", \" + df['Symptom_2'] + \", \" + df['Symptom_3'] + \", \" + df['Symptom_4']\n",
    "\n",
    "# Re-apply Doctor Logic\n",
    "def assign_doctor(disease):\n",
    "    disease = disease.lower()\n",
    "    if 'heart' in disease or 'cardio' in disease:\n",
    "        return {'Specialist': 'Cardiologist', 'Name': 'Dr. A. Sharma', 'Time': '10:00 AM - 2:00 PM', 'Location': 'City Heart Center, Delhi'}\n",
    "    elif 'fungal' in disease or 'skin' in disease or 'rash' in disease:\n",
    "        return {'Specialist': 'Dermatologist', 'Name': 'Dr. P. Verma', 'Time': '4:00 PM - 8:00 PM', 'Location': 'Skin Care Clinic, Mumbai'}\n",
    "    elif 'stomach' in disease or 'digestion' in disease:\n",
    "        return {'Specialist': 'Gastroenterologist', 'Name': 'Dr. R. Gupta', 'Time': '11:00 AM - 3:00 PM', 'Location': 'Digestive Care, Bangalore'}\n",
    "    else:\n",
    "        return {'Specialist': 'General Physician', 'Name': 'Dr. S. Kumar', 'Time': '9:00 AM - 5:00 PM', 'Location': 'City Hospital, Main Wing'}\n",
    "\n",
    "doctor_info = df['Disease'].apply(assign_doctor)\n",
    "df['Doctor_Name'] = doctor_info.apply(lambda x: x['Name'])\n",
    "df['Doctor_Specialist'] = doctor_info.apply(lambda x: x['Specialist'])\n",
    "df['Doctor_Time'] = doctor_info.apply(lambda x: x['Time'])\n",
    "df['Doctor_Location'] = doctor_info.apply(lambda x: x['Location'])\n",
    "\n",
    "# 2. CREATE EMBEDDINGS (The \"Brain\")\n",
    "print(\"Loading Embedding Model...\")\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"Generating vectors for all diseases... (This takes a moment)\")\n",
    "# We convert all symptoms text into numbers\n",
    "symptom_vectors = embedding_model.embed_documents(df['Combined_Symptoms'].tolist())\n",
    "\n",
    "# 3. BUILD SEARCH ENGINE (Using Scikit-Learn)\n",
    "print(\"Building Search Engine...\")\n",
    "# We use NearestNeighbors to find the closest matching vector\n",
    "knn = NearestNeighbors(n_neighbors=1, metric='cosine')\n",
    "knn.fit(symptom_vectors)\n",
    "\n",
    "print(\"‚úÖ Success! The chatbot brain is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a3081e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Sehat Sathi is Ready! (Type 'quit' to stop)\n",
      "------------------------------------------------\n",
      "\n",
      "üë§ You (Hindi/English): ‡§Æ‡•Å‡§ù‡•á ‡§§‡•ç‡§µ‡§ö‡§æ ‡§™‡§∞ ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§ú‡§≤‡•Ä ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à\n",
      "ü§ñ Thinking...\n",
      "ü§ñ Sehat Sathi: ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ï‡•ç‡§∑‡§£‡•ã‡§Ç ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞, ‡§ê‡§∏‡§æ ‡§≤‡§ó‡§§‡§æ ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§ö‡§ø‡§ï‡§® ‡§™‡•â‡§ï‡•ç‡§∏ ‡§π‡•à‡•§\n",
      "\n",
      "üíä‡§â‡§™‡§æ‡§Ø: ‡§â‡§ö‡§ø‡§§ ‡§â‡§™‡§ö‡§æ‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§≤‡•á‡§Ç‡•§\n",
      "\n",
      "üë®‚Äç‚öïÔ∏è ‡§∏‡•Å‡§ù‡§æ‡§è ‡§ó‡§è ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§ï‡•Ä ‡§®‡§ø‡§Ø‡•Å‡§ï‡•ç‡§§‡§ø:\n",
      "   - ‡§®‡§æ‡§Æ: ‡§°‡•â. ‡§è‡§∏. ‡§ï‡•Å‡§Æ‡§æ‡§∞ (‡§ú‡§®‡§∞‡§≤ ‡§´‡§ø‡§ú‡§ø‡§∂‡§ø‡§Ø‡§®)\n",
      "   - ‡§∏‡§Æ‡§Ø: ‡§∏‡•Å‡§¨‡§π 9:00 ‡§¨‡§ú‡•á ‡§∏‡•á ‡§∂‡§æ‡§Æ 5:00 ‡§¨‡§ú‡•á ‡§§‡§ï\n",
      "   - ‡§∏‡•ç‡§•‡§æ‡§®: ‡§∏‡§ø‡§ü‡•Ä ‡§π‡•â‡§∏‡•ç‡§™‡§ø‡§ü‡§≤, ‡§Æ‡•á‡§® ‡§µ‡§ø‡§Ç‡§ó\n",
      "\n",
      "üë§ You (Hindi/English): ‡§Æ‡•Å‡§ù‡•á ‡§∏‡•Ä‡§®‡•á ‡§Æ‡•á‡§Ç ‡§¶‡§∞‡•ç‡§¶ ‡§π‡•à\n",
      "ü§ñ Thinking...\n",
      "ü§ñ Sehat Sathi: ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ï‡•ç‡§∑‡§£‡•ã‡§Ç ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§ê‡§∏‡§æ ‡§≤‡§ó‡§§‡§æ ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§¶‡§ø‡§≤ ‡§ï‡§æ ‡§¶‡•å‡§∞‡§æ ‡§™‡§°‡§º‡§æ ‡§π‡•à‡•§\n",
      "\n",
      "üíä‡§â‡§™‡§æ‡§Ø: ‡§â‡§ö‡§ø‡§§ ‡§â‡§™‡§ö‡§æ‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§≤‡•á‡§Ç‡•§\n",
      "\n",
      "üë®‚Äç‚öïÔ∏è ‡§∏‡•Å‡§ù‡§æ‡§è ‡§ó‡§è ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§ï‡•Ä ‡§®‡§ø‡§Ø‡•Å‡§ï‡•ç‡§§‡§ø:\n",
      "   - ‡§®‡§æ‡§Æ: ‡§°‡•â. ‡§è. ‡§∂‡§∞‡•ç‡§Æ‡§æ (‡§π‡•É‡§¶‡§Ø ‡§∞‡•ã‡§ó ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û)\n",
      "   - ‡§∏‡§Æ‡§Ø: ‡§∏‡•Å‡§¨‡§π 10:00 ‡§¨‡§ú‡•á ‡§∏‡•á ‡§¶‡•ã‡§™‡§π‡§∞ 2:00 ‡§¨‡§ú‡•á ‡§§‡§ï\n",
      "   - ‡§∏‡•ç‡§•‡§æ‡§®: ‡§∏‡§ø‡§ü‡•Ä ‡§π‡§æ‡§∞‡•ç‡§ü ‡§∏‡•á‡§Ç‡§ü‡§∞, ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import time\n",
    "\n",
    "def find_best_match(user_query):\n",
    "    # 1. Translate Hindi Query -> English (for the database)\n",
    "    translator_en = GoogleTranslator(source='auto', target='en')\n",
    "    query_en = translator_en.translate(user_query)\n",
    "    \n",
    "    # 2. Convert Query to Numbers (Vector)\n",
    "    query_vector = embedding_model.embed_query(query_en)\n",
    "    \n",
    "    # 3. Find Closest Match\n",
    "    # reshapes vector to match format expected by knn\n",
    "    distances, indices = knn.kneighbors([query_vector])\n",
    "    \n",
    "    # Get the best matching row from our Data\n",
    "    best_match_index = indices[0][0]\n",
    "    result = df.iloc[best_match_index]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def chat_interface():\n",
    "    print(\"ü§ñ Sehat Sathi is Ready! (Type 'quit' to stop)\")\n",
    "    print(\"------------------------------------------------\")\n",
    "    \n",
    "    translator_hi = GoogleTranslator(source='auto', target='hi')\n",
    "    \n",
    "    while True:\n",
    "        # Get User Input\n",
    "        user_input = input(\"\\nüë§ You (Hindi/English): \")\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', 'stop']:\n",
    "            print(\"ü§ñ Sehat Sathi: ‡§Ö‡§™‡§®‡§æ ‡§ñ‡•ç‡§Ø‡§æ‡§≤ ‡§∞‡§ñ‡•á‡§Ç! (Take care!)\")\n",
    "            break\n",
    "        \n",
    "        print(\"ü§ñ Thinking...\")\n",
    "        \n",
    "        try:\n",
    "            # Find the best medical match\n",
    "            match = find_best_match(user_input)\n",
    "            \n",
    "            # Construct the English Answer\n",
    "            response_en = (\n",
    "                f\"Based on your symptoms, it seems like you have {match['Disease']}.\\n\\n\"\n",
    "                f\"üíä Remedy: {match['Remedies']}\\n\\n\"\n",
    "                f\"üë®‚Äç‚öïÔ∏è Suggested Doctor Appointment:\\n\"\n",
    "                f\"   - Name: {match['Doctor_Name']} ({match['Doctor_Specialist']})\\n\"\n",
    "                f\"   - Time: {match['Doctor_Time']}\\n\"\n",
    "                f\"   - Location: {match['Doctor_Location']}\\n\"\n",
    "            )\n",
    "            \n",
    "            # Translate Answer to Hindi\n",
    "            response_hi = translator_hi.translate(response_en)\n",
    "            \n",
    "            # Display Output\n",
    "            print(f\"ü§ñ Sehat Sathi: {response_hi}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# START THE CHAT\n",
    "chat_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf68ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-05 14:32:01.294 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.297 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.299 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.302 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.303 Session state does not function when running a script without `streamlit run`\n",
      "2026-01-05 14:32:01.305 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.311 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.316 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.318 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.324 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.326 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.329 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.330 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.332 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.333 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.336 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.337 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.340 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.346 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.355 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.360 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.363 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.370 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.372 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.373 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.375 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.377 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.380 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.382 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.388 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.391 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.395 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.402 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.403 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.405 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.407 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.409 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.411 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.414 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.415 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.418 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.420 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.422 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.423 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.425 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.427 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-05 14:32:01.433 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c1754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
